{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Docker Spark setup\n",
    "\n",
    "This notebook is meant to run on a spark 2 docker container. First i'll describe the steps to set it up.\n",
    "\n",
    "On a Linux based system install Docker and Docker-compose.Create this file : docker-compose.yml. The contents is listed below. Notice originally both spark master and worker use the singularities/spark im image. Spark-image is the new new after docker commit statements.  Then run: docker-compose build . Afterwards run this command : docker-compose build -d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "version: \"2\"\n",
    "\n",
    "services:\n",
    "  master:\n",
    "    image: spark-michel\n",
    "    command: start-spark master\n",
    "    hostname: master\n",
    "    ports:\n",
    "      - \"6066:6066\"\n",
    "      - \"7070:7070\"\n",
    "      - \"8080:8080\"\n",
    "      - \"50070:50070\"\n",
    "      - \"8888:8888\"\n",
    "    volumes:\n",
    "      - /Users/michelnossin/Downloads/fr24:/root/fr24\n",
    "  worker:\n",
    "    image: singularities/spark\n",
    "    command: start-spark worker master\n",
    "    environment:\n",
    "      SPARK_WORKER_CORES: 1\n",
    "      SPARK_WORKER_MEMORY: 2g\n",
    "    links:\n",
    "      - master\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "With docker ps , check if the master and worker containers are running.\n",
    "Connect to the master node:\n",
    "docker exec -it [container id master] bash\n",
    "On the master node continue with setting up as described below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Spark and conda env setup\n",
    "\n",
    "```\n",
    "First install Anaconda 4 (latest version) on the Docker container with Spark Master. Then install a new Conda environment for Spark, using python 3.5 (3.6 has a bug).  \n",
    "\n",
    "conda create -n spark python=3.5\n",
    "source activate spark\n",
    "conda install notebook ipykernel\n",
    "ipython kernel install --user --name spark --display-name spark\n",
    "\n",
    "Make jupyter start script, and run it:\n",
    "PYSPARK_PYTHON=/root/anaconda3/envs/spark/bin/python\n",
    "PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --ip=0.0.0.0 --port=8888' $SPARK_HOME/bin/pyspark\n",
    "\n",
    "Now go to the url it gives (http://0.0.0.0:8888/<some code>)\n",
    ", Run the nodebook sections.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Start this in spark conda env to test\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types as typ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example data\n",
    "\n",
    "```\n",
    "This example works if you clone https://github.com/PacktPublishing/Learning-PySpark\n",
    "\n",
    "and make sure its in /root/learningPySpark on the Docker container with Spark Master. \n",
    "\n",
    "To install git on this container run command: apt-get install git\n",
    ", on github (or bitbucket) create a repository so you can save changes from the container and push it to Github. Use the following commands on the Docker container to init and push the data :\n",
    "\n",
    "git init\n",
    "git add <your file>\n",
    "git commit -m \"first commit\"\n",
    "git remote add origin https://github.com/michelnossin/pyspark_training_docker.git\n",
    "git push -u origin master\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: string, distance: string, origin: string, destination: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RANDOM FLIGHTS SET, AND WORLD AIRPORT SET\n",
    "flights = \"file:/root/learningPySpark/Chapter03/flight-data/departuredelays.csv\" \n",
    "airports = \"file:/root/learningPySpark/Chapter03/flight-data/airport-codes-na.txt\" \n",
    "airports_df = spark.read.csv(airports,header='true',inferSchema='true',sep='\\t')\n",
    "airports_df.createOrReplaceTempView(\"airports\")\n",
    "flights_df = spark.read.csv(flights,header='true')\n",
    "flights_df.createOrReplaceTempView(\"flights\")\n",
    "flights_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[na: string, altitude: string, dest: string, heading: string, flight: string, fltid: string, landed: string, time: string, lat: string, lon: string, na3: string, org: string, na4: string, registration: string, flight2: string, speed: string, na6: string, planetype: string, altitude_delta: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RADAR TRACK\n",
    "track_file = \"file:/root/fr24/fr24_20160624.csv\"\n",
    "header=['na','altitude','dest','heading','flight','fltid','landed','time','lat',\\\n",
    "         'lon','na3','org','na4','registration','flight2','speed','na6','planetype', 'altitude_delta']\n",
    "fields = [ *[\n",
    "           typ.StructField(h, typ.StringType(), True)\n",
    "           for h in header\n",
    "       ]\n",
    "   ]\n",
    "schema = typ.StructType(fields)\n",
    "schema   \n",
    "tracks_df = spark.read.csv(track_file,header='false',schema=schema)\n",
    "\n",
    "#filter tracks early to make it speed up\n",
    "tracks_df = tracks_df.where(\"dest == 'AMS'\") #14 milj -> 114k\n",
    "tracks_df.createOrReplaceTempView(\"tracks\")\n",
    "tracks_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Alternatively use correct schema from beginning:\n",
    "import pyspark.sql.types as typ\n",
    "   labels = [\n",
    "       ('INFANT_ALIVE_AT_REPORT', typ.IntegerType()),\n",
    "       ('BIRTH_PLACE', typ.StringType()),\n",
    "       ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "       ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "       ('CIG_BEFORE', typ.IntegerType()),\n",
    "       ('CIG_1_TRI', typ.IntegerType()),\n",
    "       ('CIG_2_TRI', typ.IntegerType()),\n",
    "       ('CIG_3_TRI', typ.IntegerType()),\n",
    "       ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "       ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "       ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "       ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "       ('DIABETES_PRE', typ.IntegerType()),\n",
    "       ('DIABETES_GEST', typ.IntegerType()),\n",
    "       ('HYP_TENS_PRE', typ.IntegerType()),\n",
    "       ('HYP_TENS_GEST', typ.IntegerType()),\n",
    "       ('PREV_BIRTH_PRETERM', typ.IntegerType())\n",
    "   ]\n",
    "   schema = typ.StructType([\n",
    "       typ.StructField(e[0], e[1], False) for e in labels\n",
    "   ])\n",
    "   births = spark.read.csv('births_transformed.csv.gz',\n",
    "                           header=True,\n",
    "                           schema=schema)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## First look at data:\n",
    "\n",
    "```\n",
    "source activate spark\n",
    "python -m pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select count(1) from flights\").show()\n",
    "spark.sql(\"select count(1) from airports\").show()\n",
    "spark.sql(\"select count(1) from tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flights_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flights_df.printSchema() #date, delay and distance should change to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cleaning data\n",
    "\n",
    "Your data can be stained with duplicates, missing observations and outliers, non- existent addresses, wrong phone numbers and area codes, inaccurate geographical coordinates, wrong dates, incorrect labels, mixtures of upper and lower cases, trailing spaces, and many other more subtle problems. It is your job to clean it, irrespective of whether you are a data scientist or data engineer,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Duplicate rows check and remove\n",
    "First lets define some our spark util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showDuplicateRowsCount(df):\n",
    "    'Show row count with full duplicated rows'\n",
    "    print(\"====Checking table duplicate rows =====\")\n",
    "    print('Count of rows: {0}'.format(df.count()))\n",
    "    print('Count of distinct rows: {0}'.format(df.distinct().count()))\n",
    "    print('===> nr of duplicate rows {0}'.format(df.count()-df.distinct().count()))\n",
    "def showDuplicatesColumnCount(df,col):\n",
    "    'Show duplicate rows based on a specific (id) col.'\n",
    "    print(\"=====Checking col {0}\".format(col))\n",
    "    print('Count of values: {0}'.format(df.count()))\n",
    "    distinct_col_count = df.select([\n",
    "           c for c in df.columns if c != col\n",
    "       ]).distinct().count()\n",
    "    print('Count of distinct column values: {0}'.format(distinct_col_count))\n",
    "    print (\"====> duplicate count {0}\".format(df.count() - distinct_col_count))\n",
    "def showDuplicatesColumnCountSpark(df,col):\n",
    "    'spark version of Showduplicatescolumncount()'\n",
    "    df.agg(\n",
    "       fn.count(col).alias('count'),\n",
    "       fn.countDistinct(col).alias('distinct')\n",
    "    ).show()\n",
    "def showDuplicateColumnsCount(df):\n",
    "    'Show duplicate rows based on all columns in a dataframe'\n",
    "    for col in df.columns:\n",
    "        showDuplicatesColumn(df,col)\n",
    "def dropDuplicateColumn(df,col):\n",
    "    'drop rows with duplicate columns based on certain (id) column'\n",
    "    df = df.dropDuplicates(subset=[\n",
    "       c for c in df.columns if c != col\n",
    "    ])\n",
    "#   \n",
    "#def getDFDuplicateColumns(df,col,new_col):\n",
    "#    uniq_df = df.select([\n",
    "#           c for c in df.columns if c != col\n",
    "#       ]).distinct()\n",
    "#    duplicate_df = df.subtract(uniq_df)\n",
    "#    \n",
    "#    return(duplicate_df.withColumn(new_col, \\\n",
    "#                            fn.monotonically_increasing_id()))\n",
    "#   **/ \n",
    "def showMissingDataPercent(df_miss):\n",
    "    'show each column and percentage of missing data, 0 - 1 , 0 means no missing data'\n",
    "    df_miss.agg(*[\n",
    "       (1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing')\n",
    "       for c in df_miss.columns\n",
    "    ]).show()\n",
    "def getDFDropColumn(df_miss,col):\n",
    "    'Get a new dataframe based on another without given column'\n",
    "    return(df_miss.select([\n",
    "       c for c in df_miss.columns if c != col\n",
    "    ]))\n",
    "def getDFDropMissingRows(df_miss):\n",
    "    'Drop rows with any missing column field'\n",
    "    return(df_miss.dropna())\n",
    "def fillMissingMeanColumn(df,col):\n",
    "    'Fill in missing values in a certain column containing numerical data'\n",
    "    means = df.agg(\n",
    "       *[fn.mean(col).alias(col)\n",
    "           for c in df.columns if c != col]\n",
    "   ).toPandas().to_dict('records')[0]\n",
    "def getDFFillMissingCategoryColumn(df,col):\n",
    "    'Fill in missing values in a column containing a category and return df'\n",
    "    miss_dict = {col: \"missing\"}\n",
    "    return(df.fillna(miss_dict))\n",
    "def getDictOutliers(df_outliers,col_list):\n",
    "    'return dictionary with outliers boundaries , based on columns in list'\n",
    "    bounds = {}\n",
    "    for col in col_list:\n",
    "        quantiles = df_outliers.approxQuantile(\n",
    "           col, [0.25, 0.75], 0.05\n",
    "       )\n",
    "        IQR = quantiles[1] - quantiles[0]\n",
    "        bounds[col] = [\n",
    "           quantiles[0] - 1.5 * IQR,\n",
    "           quantiles[1] + 1.5 * IQR\n",
    "     ]\n",
    "    return bounds\n",
    "def getDFOutliers(df_outliers,bounds,cols,id_col):\n",
    "    'print all outlier rows based on dictionary with outlier bounderies dict, for columns in column list'\n",
    "    outliers = df_outliers.select(*[id_col] + [\n",
    "       (\n",
    "           (df_outliers[c] < bounds[c][0]) |\n",
    "           (df_outliers[c] > bounds[c][1])\n",
    "       ).alias(c + '_o') for c in cols\n",
    "    ])\n",
    "    return outliers\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Check duplicates rows, same value?\n",
    "flights_df = spark.sql(\"select * from flights\") #507 out of 1.4 milj\n",
    "showDuplicateRowsCount(flights_df)\n",
    "airports_df = spark.sql(\"select * from airports\") #0\n",
    "showDuplicateRowsCount(airports_df)\n",
    "tracks_df = spark.sql(\"select * from tracks\") #192k out of 14m, 735 out of 114k after filtering for AMS arrival\n",
    "showDuplicateRowsCount(tracks_df) #takes 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Change type of integer based columns , so we check outliers later on\n",
    "flights_df = flights_df.withColumn(\"delay\",flights_df[\"delay\"].cast(typ.IntegerType()))\n",
    "flights_df = flights_df.withColumn(\"distance\",flights_df[\"distance\"].cast(typ.IntegerType()))\n",
    "                   \n",
    "tracks_df = tracks_df.withColumn(\"altitude\",tracks_df[\"altitude\"].cast(typ.IntegerType()))  \n",
    "tracks_df = tracks_df.withColumn(\"altitude_delta\",tracks_df[\"altitude_delta\"].cast(typ.IntegerType()))\n",
    "tracks_df = tracks_df.withColumn(\"speed\",tracks_df[\"speed\"].cast(typ.IntegerType()))      \n",
    "tracks_df = tracks_df.withColumn(\"heading\",tracks_df[\"heading\"].cast(typ.IntegerType()))   \n",
    "tracks_df = tracks_df.withColumn(\"lat\",tracks_df[\"lat\"].cast(typ.FloatType()))  \n",
    "tracks_df = tracks_df.withColumn(\"lon\",tracks_df[\"lon\"].cast(typ.FloatType())) \n",
    "tracks_df = tracks_df.withColumn(\"time\",tracks_df[\"time\"].cast(typ.LongType())) \n",
    "tracks_df = tracks_df.withColumn(\"landed\",tracks_df[\"landed\"].cast(typ.IntegerType()))\n",
    "\n",
    "#Lets add a id columns for the flights\n",
    "flights_df = flights_df.withColumn('id',fn.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pure duplicates just drop these, but the flights tables might be different flights. We donts know without id\n",
    "tracks_df =tracks_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Duplicate columns check\n",
    "\n",
    "Some times there are columns identifying a row, and which are different.\n",
    "However in case you know the rest of the columns is the same you might want to remove these rows. eg , Michel , 1.90, hoofddorp , and michel2, 1.90, hoofddorp . Its the same person but id is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#airports IATA should be uniq. It seems 15 rows have identical data \n",
    "#but different IATA code\n",
    "showDuplicatesColumnCount(airports_df,'IATA')\n",
    "showDuplicatesColumnCountSpark(airports_df,'IATA')\n",
    "#TODO WHY ARE RESULT DIFFERENT!!!!!! SHOULD BE BOTH 511 OR 524!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "showDuplicatesColumnCount(tracks_df,'flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "We could call dropDuplicateColumn(df_airports,'IATA')\n",
    "\n",
    "However this would delete rows without knowing the correct IATA. \n",
    "The Flights tables does not have uniq field like flightname,\n",
    "so will not delete any rows there either.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#TODO: Make function to show these rows so we know which are duplicates\n",
    "#df_duplicate_airports = getDFDuplicateColumns(airports_df,'IATA','new_id')\n",
    "#df_duplicate_airports.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Missing data\n",
    "\n",
    "```\n",
    "Drop data row if possible in case of missing. if datasize. < 50% check which features are missing, and just drop these.\n",
    "Alternative impute missing:\n",
    "Boolean: add missing category\n",
    "categorial already: add multiple extra levels and and missing there\n",
    "numeric and ordinal: mean, median etc to fill in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#0 = perfect, 1 = all is missing\n",
    "showMissingDataPercent(airports_df) #State misses some data\n",
    "showMissingDataPercent(flights_df)\n",
    "showMissingDataPercent(tracks_df) #We miss some, flight a bit, but is important to have these,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We could just drop column state, we keep all our rows, and have no missing data\n",
    "df_no_state = getDFDropColumn(airports_df,'State')\n",
    "showMissingDataPercent(df_no_state)\n",
    "\n",
    "df_no_flight = getDFDropColumn(tracks_df,'flight')\n",
    "showMissingDataPercent(df_no_flight)\n",
    "\n",
    "df_no_flight.count() #113993 out of 114k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n",
      "+----------+----------------+------------+---------------+--------------+-------------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-------------+-----------+-----------------+----------------------+\n",
      "|na_missing|altitude_missing|dest_missing|heading_missing|flight_missing|fltid_missing|landed_missing|time_missing|lat_missing|lon_missing|na3_missing|org_missing|na4_missing|registration_missing|flight2_missing|speed_missing|na6_missing|planetype_missing|altitude_delta_missing|\n",
      "+----------+----------------+------------+---------------+--------------+-------------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-------------+-----------+-----------------+----------------------+\n",
      "|       0.0|             0.0|         0.0|            0.0|           0.0|          0.0|           0.0|         0.0|        0.0|        0.0|        0.0|        0.0|        0.0|                 0.0|            0.0|          0.0|        0.0|              0.0|                   0.0|\n",
      "+----------+----------------+------------+---------------+--------------+-------------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-------------+-----------+-----------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113167"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Or drop only rows with any missing data\n",
    "df_without_missing = getDFDropMissingRows(airports_df)\n",
    "showMissingDataPercent(df_without_missing)\n",
    "\n",
    "df_without_missing_flight = getDFDropMissingRows(tracks_df)\n",
    "showMissingDataPercent(df_without_missing_flight)\n",
    "\n",
    "df_without_missing_flight.count() #Also 113167 , so we could just use this for the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-------+----+\n",
      "|         City|  State|Country|IATA|\n",
      "+-------------+-------+-------+----+\n",
      "|Washington DC|missing|    USA| IAD|\n",
      "|Washington DC|missing|    USA| DCA|\n",
      "|Washington DC|missing|    USA| WAS|\n",
      "+-------------+-------+-------+----+\n",
      "\n",
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Or we can impute values, as this is a category we will add a missing category\n",
    "df_missing_state = getDFFillMissingCategoryColumn(airports_df,'State')\n",
    "df_missing_state.where(\"State == 'missing'\").show() #3\n",
    "df_missing_state.count() #526\n",
    "showMissingDataPercent(df_missing_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#LETS PICK LAST OPTION for Airports and trackers\n",
    "airports_df = df_missing_state\n",
    "tracks_df = df_without_missing_flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### outliers\n",
    "\n",
    "Outliers are those observations that deviate signi cantly from the distribution of the rest of your sample. The de nitions of signi cance vary, but in the most general form, you can accept that there are no outliers if all the values are roughly within the Q1âˆ’1.5IQR and Q3+1.5IQR range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Show the ouytlier ranges for our integer based columns\n",
    "col_list = ['delay','distance'] \n",
    "\n",
    "#Run cast code in the beginning again (dont no why thats needed?)\n",
    "outliers_dict = getDictOutliers(flights_df,col_list)\n",
    "print(outliers_dict) \n",
    "\n",
    "#Show the ouytlier ranges for our integer based columns\n",
    "col_flights_list = ['lat','lon','altitude','heading','time','landed'] \n",
    "\n",
    "outliers_flights_dict = getDictOutliers(tracks_df,col_flights_list)\n",
    "print(outliers_flights_dict) #Not really handy way to check outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Flag rows\n",
    "#Run the id add function again, for some reason..\n",
    "df_outliers = getDFOutliers(flights_df,outliers_dict,col_list,'id')\n",
    "df_outliers.show()\n",
    "\n",
    "df_flight_outliers = getDFOutliers(tracks_df,outliers_flights_dict,col_flights_list,'flight')\n",
    "df_flight_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Show outlier  flights\n",
    "#1.4 milj flights, about 162k has outlier delays. And 75k outlier distance\n",
    "df_out= flights_df.join(df_outliers, on='id')\n",
    "print(df_out.filter('delay_o').select('id', 'delay').count())\n",
    "print(df_out.filter('distance_o').select('id', 'distance').count())\n",
    "df_out.filter('delay_o').select('id', 'delay').show()\n",
    "df_out.filter('distance_o').select('id', 'distance').show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Show outlier  tracks, dont understand the result yet .. todo\n",
    "df_out=tracks_df.join(df_flight_outliers, on='flight')\n",
    "print(df_out.filter('heading_o').select('flight', 'heading').count())  #None, however heading has strange values\n",
    "print(df_out.filter('altitude_o').select('flight', 'altitude').count()) #None, but shows some strange numbers\n",
    "print(df_out.filter('lat_o').select('flight', 'lat').count()) #32, < 33 but still good value\n",
    "print(df_out.filter('lon_o').select('flight', 'lon').count()) #-66 also good\n",
    "print(df_out.filter('landed_o').select('flight', 'landed').count())  # 0 , <> 0.0 .. \n",
    "\n",
    "df_out.filter('heading_o').select('flight', 'heading').show()\n",
    "df_out.filter('altitude_o').select('flight', 'altitude').show()\n",
    "df_out.filter('lat_o').select('flight', 'lat').show()\n",
    "df_out.filter('lon_o').select('flight', 'lon').show()\n",
    "df_out.filter('landed_o').select('flight', 'landed').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Lets filters in between known ranges:\n",
    "#landed 0 or 1\n",
    "#heading 0 - 360\n",
    "#altitude < 100 , > 50000 \n",
    "#the valid range of latitude in degrees is -90 and +90 . Longitude is in the range -180 and +180 \n",
    "tracks_df = tracks_df.where(\"landed == 0 or landed == 1\")\n",
    "tracks_df = tracks_df.where(\"heading >= 0 and heading < 360\")\n",
    "tracks_df = tracks_df.where(\"altitude > -100 and altitude < 50000\")\n",
    "tracks_df = tracks_df.where(\"lat >= -90 and lat <= 90\")\n",
    "tracks_df = tracks_df.where(\"lon >= -180 and lon <= 180\")\n",
    "tracks_df.count() #only 1 row removed 113992\n",
    "\n",
    "tracks_df.describe().toPandas() #looks fine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_sel = tracks_df.where(\"flight == 'KL836'\").toPandas().sort_values(['time']).reset_index() #515 rows\n",
    "df_sel.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import folium\n",
    "\n",
    "%matplotlib inline\n",
    "def inline_map(map):\n",
    "    \"\"\"\n",
    "    Embeds the HTML source of the map directly into the IPython notebook.\n",
    "    \n",
    "    This method will not work if the map depends on any files (json data). Also this uses\n",
    "    the HTML5 srcdoc attribute, which may not be supported in all browsers.\n",
    "    \"\"\"\n",
    "    map._build_map()\n",
    "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
    " \n",
    "def embed_map(map, path=\"map.html\"):\n",
    "    \"\"\"\n",
    "    Embeds a linked iframe to the map into the IPython notebook.\n",
    "    \n",
    "    Note: this method will not capture the source of the map into the notebook.\n",
    "    This method should work for all maps (as long as they use relative urls).\n",
    "    \"\"\"\n",
    "    map.create_map(path=path)\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.style.use('ggplot')\n",
    "df_sel[['altitude','speed']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import folium\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def display(m, height=300):\n",
    "    \"\"\"Takes a folium instance and embed HTML.\"\"\"\n",
    "    m._build_map()\n",
    "    srcdoc = m.HTML.replace('\"', '&quot;')\n",
    "    embed = HTML('<iframe srcdoc=\"{0}\" '\n",
    "                 'style=\"width: 100%; height: {1}px; '\n",
    "                 'border: none\"></iframe>'.format(srcdoc, height))\n",
    "    return embed\n",
    "\n",
    "def inline_map(map):\n",
    "    \"\"\"\n",
    "    Embeds the HTML source of the map directly into the IPython notebook.\n",
    "    \n",
    "    This method will not work if the map depends on any files (json data). Also this uses\n",
    "    the HTML5 srcdoc attribute, which may not be supported in all browsers.\n",
    "    \"\"\"\n",
    "    map._build_map()\n",
    "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
    "\n",
    "def embed_map(map, path=\"map.html\"):\n",
    "    \"\"\"\n",
    "    Embeds a linked iframe to the map into the IPython notebook.\n",
    "    \n",
    "    Note: this method will not capture the source of the map into the notebook.\n",
    "    This method should work for all maps (as long as they use relative urls).\n",
    "    \"\"\"\n",
    "    #map.create_map(path=path)\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import HTML\n",
    "def plotFlight(flight):\n",
    "    #df_sel = tracks_df.where(\"flight == '\" + flight + \"'\").toPandas().sort_values(['time']).reset_index()\n",
    "    df_sel = join_df.toPandas().query(\"flight == '\" + flight + \"'\").sort_values(['time']).reset_index()\n",
    "    fmap=folium.Map(location=[52.308871, 4.761392], zoom_start=4)\n",
    "    #for row in df_sel.iterrows():\n",
    "     #   latlon = [ row[1]['lat'], row[1]['lon'] ]\n",
    "    #   folium.Marker(latlon, popup=str(row[1]['time'])).add_to(fmap)\n",
    "     #   fmap.add_children\n",
    "    \n",
    "    \n",
    "    latlist = df_sel['lat'].tolist()\n",
    "    lonlist = df_sel['lon'].tolist()\n",
    "    coordinates = zip(latlist[:], lonlist[:])\n",
    "    line=folium.PolyLine(locations=coordinates,weight=3,color = 'red')\n",
    "    fmap.add_children(line)\n",
    "    fmap.save('osm.html')\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path='osm.html'))\n",
    "\n",
    "def plotPoint(lon,lat):\n",
    "    fmap=folium.Map(location=[52.308871, 4.761392], zoom_start=13)\n",
    "    latlon = [ lat, lon ]\n",
    "    folium.Marker(latlon, popup=str(\"test\")).add_to(fmap)\n",
    "    fmap.add_children\n",
    "    fmap.save('osm.html')\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path='osm.html'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plotFlight('Y87486')\n",
    "plotFlight('MP6742') #freight\n",
    "plotFlight('KL1326')\n",
    "#plotFlight('KL214')\n",
    "#plotFlight('KL836')\n",
    "#plotFlight('U26771')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runway_list = [   { \"runway\" : 1, \"lat\" : 52.350202, \"lon\" : 4.710732 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"polderbaan\" },\n",
    "    { \"runway\" : 2, \"lat\" : 52.316110, \"lon\" : 4.738369 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"zwanenburgbaan\" },\n",
    "    { \"runway\" : 3, \"lat\" : 52.317579, \"lon\" : 4.772186 , \"heading1\" : 90 , \"heading2\" : 270, \"name\" : \"buitenveldertbaan\" },\n",
    "    { \"runway\" : 4, \"lat\" : 52.297217, \"lon\" : 4.757938 , \"heading1\" : 60 , \"heading2\" : 240, \"name\" : \"kaagbaan\" },\n",
    "    { \"runway\" : 5, \"lat\" : 52.307714, \"lon\" : 4.778881 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"aalsmeerbaan\" },\n",
    "    { \"runway\" : 6, \"lat\" : 52.308659, \"lon\" : 4.795361 , \"heading1\" : 40 , \"heading2\" : 220, \"name\" : \"oostbaan\" }\n",
    "]\n",
    "\n",
    "pier_list = [\n",
    "        {\"id\" : 0 , \"pier\" : \"A\" , \"lon\" : 4.753781 , \"lat\" : 52.300381},\n",
    "        {\"id\" : 1 , \"pier\" : \"B\" , \"lon\" : 4.759363 , \"lat\" : 52.302362},\n",
    "        {\"id\" : 2 , \"pier\" : \"C\" , \"lon\" : 4.766188 , \"lat\" : 52.305380},\n",
    "        {\"id\" : 3 , \"pier\" : \"D\" , \"lon\" : 4.771575 , \"lat\" : 52.309147},\n",
    "        {\"id\" : 4 , \"pier\" : \"E\" , \"lon\" : 4.767366 , \"lat\" : 52.312182},\n",
    "        {\"id\" : 5 , \"pier\" : \"F\" , \"lon\" : 4.761679 , \"lat\" : 52.313040},\n",
    "        {\"id\" : 6 , \"pier\" : \"G\" , \"lon\" : 4.755998 , \"lat\" : 52.312574},\n",
    "        {\"id\" : 7 , \"pier\" : \"H\" , \"lon\" : 4.754054 , \"lat\" : 52.310135}\n",
    "    ]\n",
    "#pt = runway_list[5]\n",
    "pt = pier_list[6]\n",
    "plotPoint(pt[\"lon\"],pt[\"lat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read in the file\n",
    "flights = \"file:/root/learningPySpark/Chapter03/flight-data/departuredelays.csv\" \n",
    "fl = sc.textFile(flights) #you can use .gz, so better then spark sql\n",
    "header = fl.first()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Filter numeric columns in flights\n",
    "fl_filter = fl.filter(lambda row: row != header) \\\n",
    "       .map(lambda row: [int(elem) for elem in row.split(',') if (elem.isdigit() or elem.lstrip(\"-\").isdigit()) ])\n",
    "fl_filter.take(5) #.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create schema\n",
    "fields = [ *[\n",
    "           typ.StructField(h, typ.IntegerType(), True)\n",
    "           for h in header.split(',')\n",
    "       ]\n",
    "   ]\n",
    "schema = typ.StructType(fields)\n",
    "schema   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create DF Spark\n",
    "fli_df = spark.createDataFrame(fl_filter, schema)\n",
    "fli_df.printSchema()\n",
    "#fli_df.show() Some columns are not integer so crash, to fix later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#to group by values within a column\n",
    "tracks_df.groupby('flight').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#grouping the whole set and perform function\n",
    "tracks_df.agg({'speed' : 'skewness'}).show() #ratio mean to sd is very low, wide spread observation negatively\n",
    "\n",
    "#can also use: avg(), count(), countDistinct(), first(), kurtosis(), max(), mean(), min(), skewness(), stddev(), stddev_pop(), stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#correlation is simple (only pearson , and in pairs)\n",
    "tracks_df.corr('landed','speed') #quit some relation which you expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showCorrelationMatrix(df,numerical):\n",
    "    'for a DF print matrix with correlations between all numerical columns'\n",
    "    n_numerical = len(numerical)\n",
    "    corr = []\n",
    "    for i in range(0, n_numerical):\n",
    "        temp = [None] * i\n",
    "        for j in range(i, n_numerical):\n",
    "            temp.append(df.corr(numerical[i], numerical[j]))\n",
    "        corr.append(temp)\n",
    "        \n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "showCorrelationMatrix(tracks_df,['speed','landed','altitude','heading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.corr('speed','altitude') #very high correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lets try to make some features\n",
    "```\n",
    "Flight,time,speed,distance_to_ams,time_till_actual_landing\n",
    "\n",
    "distance to amsterdam , will be lat/lon comparison to lat/lon ams airport\n",
    "for each row\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "#This will be slow in pyspark due to context switching JVM and pyspark\n",
    "#Better to use UDF, or use Scala etc\n",
    "def dist_to_ams(lat,lon):\n",
    "    return haversine(float(4.761392), float(52.308871), float(lon),float(lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def closest_runway(lon,lat,heading):\n",
    "    \"\"\" Get closest runway at amsterdam based on plane location and heading. return code 1-12 (6 runways * 2 headings)\"\"\"\n",
    "    \n",
    "    runway_list = [   { \"runway\" : 1, \"lat\" : 52.350202, \"lon\" : 4.710732 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"polderbaan\" },\n",
    "    { \"runway\" : 2, \"lat\" : 52.316110, \"lon\" : 4.738369 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"zwanenburgbaan\" },\n",
    "    { \"runway\" : 3, \"lat\" : 52.317579, \"lon\" : 4.772186 , \"heading1\" : 90 , \"heading2\" : 270, \"name\" : \"buitenveldertbaan\" },\n",
    "    { \"runway\" : 4, \"lat\" : 52.297217, \"lon\" : 4.757938 , \"heading1\" : 60 , \"heading2\" : 240, \"name\" : \"kaagbaan\" },\n",
    "    { \"runway\" : 5, \"lat\" : 52.307714, \"lon\" : 4.778881 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"aalsmeerbaan\" },\n",
    "    { \"runway\" : 6, \"lat\" : 52.308659, \"lon\" : 4.795361 , \"heading1\" : 40 , \"heading2\" : 220, \"name\" : \"oostbaan\" }\n",
    "]\n",
    "    \n",
    "    smallest_dist_runway = -1\n",
    "    smallest_dist = -1\n",
    "    for runway in runway_list:\n",
    "        dist = haversine(float(runway[\"lon\"]), float(runway[\"lat\"]), float(lon),float(lat))\n",
    "        if smallest_dist == -1 or dist < smallest_dist:\n",
    "            smallest_dist = dist\n",
    "            smallest_dist_runway = runway\n",
    "    \n",
    "    angle1 = 180 - abs(abs(heading - smallest_dist_runway[\"heading1\"]) - 180); \n",
    "    angle2 = 180 - abs(abs(heading - smallest_dist_runway[\"heading2\"]) - 180); \n",
    "    runway_code = smallest_dist_runway[\"runway\"]\n",
    "    \n",
    "    if angle1 < angle2 :\n",
    "        return runway_code\n",
    "    return runway_code + 6\n",
    "\n",
    "def distance_to_runway(lon,lat,runway):\n",
    "    \"\"\" Get distance based on lat lon to runway given its id\"\"\"\n",
    "    runway_list = [   { \"runway\" : 1, \"lat\" : 52.350202, \"lon\" : 4.710732 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"polderbaan\" },\n",
    "    { \"runway\" : 2, \"lat\" : 52.316110, \"lon\" : 4.738369 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"zwanenburgbaan\" },\n",
    "    { \"runway\" : 3, \"lat\" : 52.317579, \"lon\" : 4.772186 , \"heading1\" : 90 , \"heading2\" : 270, \"name\" : \"buitenveldertbaan\" },\n",
    "    { \"runway\" : 4, \"lat\" : 52.297217, \"lon\" : 4.757938 , \"heading1\" : 60 , \"heading2\" : 240, \"name\" : \"kaagbaan\" },\n",
    "    { \"runway\" : 5, \"lat\" : 52.307714, \"lon\" : 4.778881 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"aalsmeerbaan\" },\n",
    "    { \"runway\" : 6, \"lat\" : 52.308659, \"lon\" : 4.795361 , \"heading1\" : 40 , \"heading2\" : 220, \"name\" : \"oostbaan\" }\n",
    "]\n",
    "    #runway code can be 1-12 (6 runways, 2 directions). So 7 means 1 + 6 , 8 means 2 + 6 etc\n",
    "    if runway > 6:\n",
    "        runway = runway - 6\n",
    "        \n",
    "    runway_lat = runway_list[runway-1][\"lat\"]\n",
    "    runway_lon = runway_list[runway-1][\"lon\"]\n",
    "    \n",
    "    return haversine(float(lon),float(lat),float(runway_lon),float(runway_lat))\n",
    "\n",
    "def distance_to_pier(lon,lat,pier):\n",
    "    \"\"\" Get distance based on lat lon to pier given its id\"\"\"\n",
    "    pier_list = [\n",
    "        {\"id\" : 0 , \"pier\" : \"A\" , \"lon\" : 4.753781 , \"lat\" : 52.300381},\n",
    "        {\"id\" : 1 , \"pier\" : \"B\" , \"lon\" : 4.759363 , \"lat\" : 52.302362},\n",
    "        {\"id\" : 2 , \"pier\" : \"C\" , \"lon\" : 4.766188 , \"lat\" : 52.305380},\n",
    "        {\"id\" : 3 , \"pier\" : \"D\" , \"lon\" : 4.771575 , \"lat\" : 52.309147},\n",
    "        {\"id\" : 4 , \"pier\" : \"E\" , \"lon\" : 4.767366 , \"lat\" : 52.312182},\n",
    "        {\"id\" : 5 , \"pier\" : \"F\" , \"lon\" : 4.761679 , \"lat\" : 52.313040},\n",
    "        {\"id\" : 6 , \"pier\" : \"G\" , \"lon\" : 4.755998 , \"lat\" : 52.312574},\n",
    "        {\"id\" : 7 , \"pier\" : \"H\" , \"lon\" : 4.754054 , \"lat\" : 52.310135}\n",
    "    ]\n",
    "        \n",
    "    pier_lat = pier_list[pier][\"lat\"]\n",
    "    pier_lon = pier_list[pier][\"lon\"]\n",
    "    \n",
    "    return haversine(float(lon),float(lat),float(pier_lon),float(pier_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_pier(lon,lat):\n",
    "    \"\"\" Get closest pier based on a location, used to predict on block time\"\"\"\n",
    "    pier_list = [\n",
    "        {\"id\" : 0 , \"pier\" : \"A\" , \"lon\" : 4.753781 , \"lat\" : 52.300381},\n",
    "        {\"id\" : 1 , \"pier\" : \"B\" , \"lon\" : 4.759363 , \"lat\" : 52.302362},\n",
    "        {\"id\" : 2 , \"pier\" : \"C\" , \"lon\" : 4.766188 , \"lat\" : 52.305380},\n",
    "        {\"id\" : 3 , \"pier\" : \"D\" , \"lon\" : 4.771575 , \"lat\" : 52.309147},\n",
    "        {\"id\" : 4 , \"pier\" : \"E\" , \"lon\" : 4.767366 , \"lat\" : 52.312182},\n",
    "        {\"id\" : 5 , \"pier\" : \"F\" , \"lon\" : 4.761679 , \"lat\" : 52.313040},\n",
    "        {\"id\" : 6 , \"pier\" : \"G\" , \"lon\" : 4.755998 , \"lat\" : 52.312574},\n",
    "        {\"id\" : 7 , \"pier\" : \"H\" , \"lon\" : 4.754054 , \"lat\" : 52.310135}\n",
    "    ]\n",
    "\n",
    "    smallest_dist_pier = -1\n",
    "    smallest_dist = -1\n",
    "    for pier in pier_list:\n",
    "        dist = haversine(float(pier[\"lon\"]), float(pier[\"lat\"]), float(lon),float(lat))\n",
    "        if smallest_dist == -1 or dist < smallest_dist:\n",
    "            smallest_dist = dist\n",
    "            smallest_dist_pier = pier\n",
    "            \n",
    "    return smallest_dist_pier[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_to_zero(some_number):\n",
    "    if some_number < 0:\n",
    "        return 0\n",
    "    return some_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "udf_func = udf(dist_to_ams, FloatType())\n",
    "tracks_df = tracks_df.withColumn(\"distance_to_ams\", \\\n",
    "                            udf_func(tracks_df.lat,tracks_df.lon))\n",
    "\n",
    "udf_func2 = udf(closest_runway, IntegerType())\n",
    "udf_func3 = udf(negative_to_zero,IntegerType())\n",
    "udf_func4 = udf(closest_pier, IntegerType())\n",
    "udf_func5 = udf(distance_to_runway,FloatType())\n",
    "udf_func6 = udf(distance_to_pier,FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Distance is great, however, after landing, the next row is the NEXT\n",
    "# flight\n",
    "df = tracks_df.where(\"flight == 'KL214'\").toPandas().sort_values(['time']).reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#just a test to compare rows\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df = (\n",
    "    sc.parallelize([\n",
    "        (134, 30, \"2016-07-02 12:01:40\"), (134, 32, \"2016-07-02 12:21:23\"),\n",
    "        (125, 30, \"2016-07-02 13:22:56\"), (125, 32, \"2016-07-02 13:27:07\"),\n",
    "    ]).toDF([\"itemid\", \"eventid\", \"timestamp\"])\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"itemid\").orderBy(\"timestamp\")\n",
    "\n",
    "diff = col(\"timestamp\").cast(\"long\") - lag(\"timestamp\", 1).over(w).cast(\"long\")\n",
    "\n",
    "df = df.withColumn(\"diff\", diff)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Lets create a delta to get the landing times\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df = (\n",
    "    sc.parallelize([\n",
    "        ('kl123', 0, \"2016-07-02 12:01:40\"), ('kl123', 0, \"2016-07-02 12:21:23\"),\n",
    "        ('kl123', 1, \"2016-07-02 13:22:56\"), ('kl123', 1, \"2016-07-02 13:27:07\"),\n",
    "    ]).toDF([\"itemid\", \"landed\", \"timestamp\"])\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"itemid\").orderBy(\"timestamp\")\n",
    "\n",
    "diff = col(\"landed\").cast(\"int\") - lag(\"landed\", 1).over(w).cast(\"int\")\n",
    "\n",
    "df = df.withColumn(\"diff\", diff)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------------+\n",
      "|flight_touchdown|runway_touchdown|time_touchdown|\n",
      "+----------------+----------------+--------------+\n",
      "|          CND518|               8|    1466792627|\n",
      "|           DL138|               1|    1466760692|\n",
      "|          MP6742|               1|    1466778285|\n",
      "|          KL1742|               2|    1466775981|\n",
      "|          U28881|               1|    1466793964|\n",
      "|          KL1134|               1|    1466796510|\n",
      "|          KL1800|               1|    1466801922|\n",
      "|          KL1858|               1|    1466777442|\n",
      "|           KL888|               1|    1466785238|\n",
      "|           OR288|               1|    1466767433|\n",
      "|          KL1618|               2|    1466749916|\n",
      "|          KL1790|               2|    1466749726|\n",
      "|           KL736|               1|    1466743064|\n",
      "|          U27908|               1|    1466800107|\n",
      "|          KL1168|               2|    1466775337|\n",
      "|          KL1010|               1|    1466769724|\n",
      "|           LH992|               1|    1466770692|\n",
      "|           LX736|               1|    1466799875|\n",
      "|           BT621|               2|    1466751644|\n",
      "|          U26771|               9|    1466763353|\n",
      "+----------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now lets adds column to show the landing moment, so delta of the landed column should be +1 .\n",
    "#\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "w = Window.partitionBy(\"flight\").orderBy(\"time\")\n",
    "\n",
    "diff = col(\"landed\").cast(\"int\") - lag(\"landed\", 1).over(w).cast(\"int\")\n",
    "tracks_touchdown_df = tracks_df.select([\"flight\",\"time\",\"lat\",\"lon\",\"heading\",\"landed\",\"registration\"]).withColumn(\"touchdown\", diff)\n",
    "tracks_touchdown_df = tracks_touchdown_df.withColumn(\"runway\", \\\n",
    "                            udf_func2(tracks_touchdown_df.lon,tracks_touchdown_df.lat,tracks_touchdown_df.heading))\n",
    "tracks_touchdown_df = tracks_touchdown_df.where(\"touchdown == 1\").select(col(\"flight\").alias(\"flight_touchdown\"), \\\n",
    "                                                                         col(\"runway\").alias(\"runway_touchdown\"), \\\n",
    "                                                                         col(\"time\").alias(\"time_touchdown\") )\n",
    "tracks_touchdown_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_touchdown_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|flight_touchdown|count|\n",
      "+----------------+-----+\n",
      "|          HV6118|    2|\n",
      "|          HV5134|    2|\n",
      "|          KL1412|    2|\n",
      "|          HV6332|    2|\n",
      "|          HV5356|   19|\n",
      "|          HV5314|    2|\n",
      "|           TP668|    2|\n",
      "|          HV6146|    2|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for multiple landings 1 flight\n",
    "#tracks_touchdown_df.groupby([\"flight\",\"registration\"]).count().where(\"count > 1\").show()\n",
    "tracks_touchdown_df.groupby([\"flight_touchdown\"]).count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#remove them\n",
    "tracks_touchdown_df = tracks_touchdown_df.where(\"flight_touchdown != 'HV6118' and flight_touchdown != 'HV5134' and flight_touchdown != 'KL1412' and flight_touchdown != 'HV6332' and flight_touchdown != 'HV5356' and flight_touchdown != 'HV5314' and flight_touchdown != 'TP668' and flight_touchdown != 'HV6146' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|flight_touchdown|count|\n",
      "+----------------+-----+\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check again\n",
    "tracks_touchdown_df.groupby([\"flight_touchdown\"]).count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#join tracks with our landing table and add column showing time till land\n",
    "join_df = tracks_df.join(tracks_touchdown_df,tracks_df.flight == tracks_touchdown_df.flight_touchdown)\n",
    "join_df = join_df.withColumn(\"time_till_landing\",col(\"time_touchdown\") - col(\"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get rid of > 7000 sec , so we make sure flights on the next day are not using the landing of current day\n",
    "join_df = join_df.where(\"time_till_landing > -7000\")\n",
    "\n",
    "#ML require positive, but we dont want to remove that, we want to calc in block time later on\n",
    "join_df = join_df.withColumn(\"time_till_landing\", udf_func3(join_df.time_till_landing))  \n",
    "join_df = join_df.withColumn(\"time_till_landing_minutes\",join_df.time_till_landing / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max,min\n",
    "\n",
    "#LEts us join_df to add the pier used to park, so we calculate on block\n",
    "maxtime_df = join_df.groupby(col(\"flight\").alias(\"flight_maxtime\")).agg(max(\"time\").alias(\"time_onblock\"))\n",
    "#join_maxtime_df = join_df.join(maxtime_df,join_df.flight == maxtime_df.flight_maxtime)\n",
    "#join_maxtime_df = join_maxtime_df.withColumn(\"time_till_onblock_minutes\",(col(\"time_onblock\") - col(\"time\")) / 60)\n",
    "\n",
    "#join_maxtime_df.toPandas().head(10) #show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onblock_df = maxtime_df.join(join_df,(maxtime_df.flight_maxtime == join_df.flight) & (maxtime_df.time_onblock == join_df.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onblock_df = onblock_df.select(col(\"flight\").alias(\"flight_onblock\"), \\\n",
    "                               col(\"lat\").alias(\"lat_onblock\"), \\\n",
    "                               col(\"lon\").alias(\"lon_onblock\"), \\\n",
    "                               col(\"time_onblock\"))\n",
    "#onblock_df.show(10)\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onblock_df = onblock_df.withColumn(\"pier_onblock\",udf_func4(col(\"lon_onblock\"),col(\"lat_onblock\")) )\n",
    "#onblock_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join_maxtime_df = join_df.join(onblock_df,join_df.flight == onblock_df.flight_onblock)\n",
    "join_maxtime_df = join_maxtime_df.withColumn(\"time_till_onblock_minutes\",(col(\"time_onblock\") - col(\"time\")) / 60)\n",
    "\n",
    "#join_maxtime_df.toPandas().head(10) #show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_df = join_maxtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join_df.toPandas().head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join_df.toPandas()['runway_touchdown'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_df = join_df.withColumn(\"distance_to_runway\",udf_func5(col(\"lon\"),col(\"lat\"),col(\"runway_touchdown\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_df = join_df.withColumn(\"distance_to_pier\",udf_func5(col(\"lon\"),col(\"lat\"),col(\"pier_onblock\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>na</th>\n",
       "      <th>altitude</th>\n",
       "      <th>dest</th>\n",
       "      <th>heading</th>\n",
       "      <th>flight</th>\n",
       "      <th>fltid</th>\n",
       "      <th>landed</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>...</th>\n",
       "      <th>time_till_landing</th>\n",
       "      <th>time_till_landing_minutes</th>\n",
       "      <th>flight_onblock</th>\n",
       "      <th>lat_onblock</th>\n",
       "      <th>lon_onblock</th>\n",
       "      <th>time_onblock</th>\n",
       "      <th>pier_onblock</th>\n",
       "      <th>time_till_onblock_minutes</th>\n",
       "      <th>distance_to_runway</th>\n",
       "      <th>distance_to_pier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>322</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466786890</td>\n",
       "      <td>45.443802</td>\n",
       "      <td>16.942801</td>\n",
       "      <td>...</td>\n",
       "      <td>5737</td>\n",
       "      <td>95.616667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>100.883333</td>\n",
       "      <td>1171.446899</td>\n",
       "      <td>1168.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>309</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466788240</td>\n",
       "      <td>47.907600</td>\n",
       "      <td>14.943300</td>\n",
       "      <td>...</td>\n",
       "      <td>4387</td>\n",
       "      <td>73.116667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>78.383333</td>\n",
       "      <td>875.597168</td>\n",
       "      <td>872.747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>326</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>1</td>\n",
       "      <td>1466792817</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.759000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.426841</td>\n",
       "      <td>1.505711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>322</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466786574</td>\n",
       "      <td>44.901600</td>\n",
       "      <td>17.529200</td>\n",
       "      <td>...</td>\n",
       "      <td>6053</td>\n",
       "      <td>100.883333</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>106.150000</td>\n",
       "      <td>1246.619141</td>\n",
       "      <td>1243.848999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10850</td>\n",
       "      <td>AMS</td>\n",
       "      <td>343</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466784462</td>\n",
       "      <td>41.194099</td>\n",
       "      <td>20.736401</td>\n",
       "      <td>...</td>\n",
       "      <td>8165</td>\n",
       "      <td>136.083333</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>141.350000</td>\n",
       "      <td>1727.837769</td>\n",
       "      <td>1725.117798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>309</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466788298</td>\n",
       "      <td>47.987598</td>\n",
       "      <td>14.800400</td>\n",
       "      <td>...</td>\n",
       "      <td>4329</td>\n",
       "      <td>72.150000</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>77.416667</td>\n",
       "      <td>861.744568</td>\n",
       "      <td>858.894226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>36000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>311</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466790974</td>\n",
       "      <td>51.670502</td>\n",
       "      <td>7.977600</td>\n",
       "      <td>...</td>\n",
       "      <td>1653</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>32.816667</td>\n",
       "      <td>232.944443</td>\n",
       "      <td>230.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>309</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466789568</td>\n",
       "      <td>49.727402</td>\n",
       "      <td>11.632400</td>\n",
       "      <td>...</td>\n",
       "      <td>3059</td>\n",
       "      <td>50.983333</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>560.881836</td>\n",
       "      <td>558.015015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>308</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466789758</td>\n",
       "      <td>49.982498</td>\n",
       "      <td>11.143100</td>\n",
       "      <td>...</td>\n",
       "      <td>2869</td>\n",
       "      <td>47.816667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>53.083333</td>\n",
       "      <td>516.037781</td>\n",
       "      <td>513.166992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>327</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466785879</td>\n",
       "      <td>43.567200</td>\n",
       "      <td>18.542200</td>\n",
       "      <td>...</td>\n",
       "      <td>6748</td>\n",
       "      <td>112.466667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>5</td>\n",
       "      <td>117.733333</td>\n",
       "      <td>1410.208984</td>\n",
       "      <td>1407.467896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  na  altitude dest  heading  flight    fltid  landed        time        lat  \\\n",
       "0  0     38000  AMS      322  CND518  a20c9e8       0  1466786890  45.443802   \n",
       "1  0     38000  AMS      309  CND518  a20c9e8       0  1466788240  47.907600   \n",
       "2  0         0  AMS      326  CND518  a20c9e8       1  1466792817  52.313702   \n",
       "3  0     38000  AMS      322  CND518  a20c9e8       0  1466786574  44.901600   \n",
       "4  0     10850  AMS      343  CND518  a20c9e8       0  1466784462  41.194099   \n",
       "5  0     38000  AMS      309  CND518  a20c9e8       0  1466788298  47.987598   \n",
       "6  0     36000  AMS      311  CND518  a20c9e8       0  1466790974  51.670502   \n",
       "7  0     38000  AMS      309  CND518  a20c9e8       0  1466789568  49.727402   \n",
       "8  0     38000  AMS      308  CND518  a20c9e8       0  1466789758  49.982498   \n",
       "9  0     38000  AMS      327  CND518  a20c9e8       0  1466785879  43.567200   \n",
       "\n",
       "         lon        ...        time_till_landing time_till_landing_minutes  \\\n",
       "0  16.942801        ...                     5737                 95.616667   \n",
       "1  14.943300        ...                     4387                 73.116667   \n",
       "2   4.759000        ...                        0                  0.000000   \n",
       "3  17.529200        ...                     6053                100.883333   \n",
       "4  20.736401        ...                     8165                136.083333   \n",
       "5  14.800400        ...                     4329                 72.150000   \n",
       "6   7.977600        ...                     1653                 27.550000   \n",
       "7  11.632400        ...                     3059                 50.983333   \n",
       "8  11.143100        ...                     2869                 47.816667   \n",
       "9  18.542200        ...                     6748                112.466667   \n",
       "\n",
       "  flight_onblock lat_onblock lon_onblock  time_onblock pier_onblock  \\\n",
       "0         CND518   52.313702      4.7589    1466792943            5   \n",
       "1         CND518   52.313702      4.7589    1466792943            5   \n",
       "2         CND518   52.313702      4.7589    1466792943            5   \n",
       "3         CND518   52.313702      4.7589    1466792943            5   \n",
       "4         CND518   52.313702      4.7589    1466792943            5   \n",
       "5         CND518   52.313702      4.7589    1466792943            5   \n",
       "6         CND518   52.313702      4.7589    1466792943            5   \n",
       "7         CND518   52.313702      4.7589    1466792943            5   \n",
       "8         CND518   52.313702      4.7589    1466792943            5   \n",
       "9         CND518   52.313702      4.7589    1466792943            5   \n",
       "\n",
       "  time_till_onblock_minutes  distance_to_runway  distance_to_pier  \n",
       "0                100.883333         1171.446899       1168.669922  \n",
       "1                 78.383333          875.597168        872.747070  \n",
       "2                  2.100000            1.426841          1.505711  \n",
       "3                106.150000         1246.619141       1243.848999  \n",
       "4                141.350000         1727.837769       1725.117798  \n",
       "5                 77.416667          861.744568        858.894226  \n",
       "6                 32.816667          232.944443        230.040207  \n",
       "7                 56.250000          560.881836        558.015015  \n",
       "8                 53.083333          516.037781        513.166992  \n",
       "9                117.733333         1410.208984       1407.467896  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df.toPandas().head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some minor random check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.select(\"flight\").distinct().count() #747 planes, might be all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df.select(\"flight\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = join_df.toPandas().query(\"flight == 'KL214'\").sort_values(['time']).reset_index()\n",
    "join_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Machine learning some troubleshoot section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[flight: string, time_till_onblock_minutes: double, distance_to_pier: float, speed: int, pier_onblock: int, lat: float, lon: float]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = join_df.select(['flight','time_till_onblock_minutes','distance_to_pier','speed','pier_onblock','lat','lon'])\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only a third is near the pier (2 km or closer), lets see if prediction go up if we only use more precise locations\n",
    "ok_df = test_df.where(\"time_till_onblock_minutes < 1\").filter(\"distance_to_pier < 2\").select(col(\"flight\").alias(\"flight_ok\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CND518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CND518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KL1134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flight_ok\n",
       "0    CND518\n",
       "1    CND518\n",
       "2     DL138\n",
       "3     DL138\n",
       "4    KL1134"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight</th>\n",
       "      <th>time_till_landing_minutes</th>\n",
       "      <th>time_till_onblock_minutes</th>\n",
       "      <th>distance_to_ams</th>\n",
       "      <th>distance_to_runway</th>\n",
       "      <th>distance_to_pier</th>\n",
       "      <th>altitude</th>\n",
       "      <th>speed</th>\n",
       "      <th>heading</th>\n",
       "      <th>runway_touchdown</th>\n",
       "      <th>pier_onblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CND518</td>\n",
       "      <td>95.616667</td>\n",
       "      <td>100.883333</td>\n",
       "      <td>1169.708008</td>\n",
       "      <td>1171.446899</td>\n",
       "      <td>1168.669922</td>\n",
       "      <td>38000</td>\n",
       "      <td>465</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CND518</td>\n",
       "      <td>73.116667</td>\n",
       "      <td>78.383333</td>\n",
       "      <td>873.840332</td>\n",
       "      <td>875.597168</td>\n",
       "      <td>872.747070</td>\n",
       "      <td>38000</td>\n",
       "      <td>456</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CND518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.560867</td>\n",
       "      <td>1.426841</td>\n",
       "      <td>1.505711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CND518</td>\n",
       "      <td>100.883333</td>\n",
       "      <td>106.150000</td>\n",
       "      <td>1244.882324</td>\n",
       "      <td>1246.619141</td>\n",
       "      <td>1243.848999</td>\n",
       "      <td>38000</td>\n",
       "      <td>476</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CND518</td>\n",
       "      <td>136.083333</td>\n",
       "      <td>141.350000</td>\n",
       "      <td>1726.118042</td>\n",
       "      <td>1727.837769</td>\n",
       "      <td>1725.117798</td>\n",
       "      <td>10850</td>\n",
       "      <td>314</td>\n",
       "      <td>343</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CND518</td>\n",
       "      <td>72.150000</td>\n",
       "      <td>77.416667</td>\n",
       "      <td>859.987732</td>\n",
       "      <td>861.744568</td>\n",
       "      <td>858.894226</td>\n",
       "      <td>38000</td>\n",
       "      <td>456</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CND518</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>32.816667</td>\n",
       "      <td>231.215576</td>\n",
       "      <td>232.944443</td>\n",
       "      <td>230.040207</td>\n",
       "      <td>36000</td>\n",
       "      <td>473</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CND518</td>\n",
       "      <td>50.983333</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>559.123230</td>\n",
       "      <td>560.881836</td>\n",
       "      <td>558.015015</td>\n",
       "      <td>38000</td>\n",
       "      <td>464</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CND518</td>\n",
       "      <td>47.816667</td>\n",
       "      <td>53.083333</td>\n",
       "      <td>514.278992</td>\n",
       "      <td>516.037781</td>\n",
       "      <td>513.166992</td>\n",
       "      <td>38000</td>\n",
       "      <td>459</td>\n",
       "      <td>308</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CND518</td>\n",
       "      <td>112.466667</td>\n",
       "      <td>117.733333</td>\n",
       "      <td>1408.481812</td>\n",
       "      <td>1410.208984</td>\n",
       "      <td>1407.467896</td>\n",
       "      <td>38000</td>\n",
       "      <td>479</td>\n",
       "      <td>327</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CND518</td>\n",
       "      <td>82.733333</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>996.119568</td>\n",
       "      <td>997.869385</td>\n",
       "      <td>995.053528</td>\n",
       "      <td>38000</td>\n",
       "      <td>449</td>\n",
       "      <td>335</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CND518</td>\n",
       "      <td>111.450000</td>\n",
       "      <td>116.716667</td>\n",
       "      <td>1393.996826</td>\n",
       "      <td>1395.724609</td>\n",
       "      <td>1392.981934</td>\n",
       "      <td>38000</td>\n",
       "      <td>477</td>\n",
       "      <td>327</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CND518</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>91.266667</td>\n",
       "      <td>1037.474609</td>\n",
       "      <td>1039.220947</td>\n",
       "      <td>1036.418579</td>\n",
       "      <td>38000</td>\n",
       "      <td>453</td>\n",
       "      <td>335</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CND518</td>\n",
       "      <td>12.816667</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>56.418419</td>\n",
       "      <td>57.591949</td>\n",
       "      <td>55.363499</td>\n",
       "      <td>7725</td>\n",
       "      <td>320</td>\n",
       "      <td>276</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CND518</td>\n",
       "      <td>35.950000</td>\n",
       "      <td>41.216667</td>\n",
       "      <td>347.197021</td>\n",
       "      <td>348.953766</td>\n",
       "      <td>346.062073</td>\n",
       "      <td>38000</td>\n",
       "      <td>469</td>\n",
       "      <td>312</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CND518</td>\n",
       "      <td>129.883333</td>\n",
       "      <td>135.150000</td>\n",
       "      <td>1658.515015</td>\n",
       "      <td>1660.237915</td>\n",
       "      <td>1657.509033</td>\n",
       "      <td>24000</td>\n",
       "      <td>420</td>\n",
       "      <td>302</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CND518</td>\n",
       "      <td>66.850000</td>\n",
       "      <td>72.116667</td>\n",
       "      <td>785.348999</td>\n",
       "      <td>787.106201</td>\n",
       "      <td>784.253723</td>\n",
       "      <td>38000</td>\n",
       "      <td>461</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CND518</td>\n",
       "      <td>24.383333</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>189.109848</td>\n",
       "      <td>190.800507</td>\n",
       "      <td>187.919189</td>\n",
       "      <td>33350</td>\n",
       "      <td>486</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CND518</td>\n",
       "      <td>52.083333</td>\n",
       "      <td>57.350000</td>\n",
       "      <td>574.542786</td>\n",
       "      <td>576.301331</td>\n",
       "      <td>573.435791</td>\n",
       "      <td>38000</td>\n",
       "      <td>463</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CND518</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>9.516667</td>\n",
       "      <td>16.019865</td>\n",
       "      <td>15.226078</td>\n",
       "      <td>16.241917</td>\n",
       "      <td>2200</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CND518</td>\n",
       "      <td>81.583333</td>\n",
       "      <td>86.850000</td>\n",
       "      <td>981.617554</td>\n",
       "      <td>983.368530</td>\n",
       "      <td>980.547852</td>\n",
       "      <td>38000</td>\n",
       "      <td>450</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CND518</td>\n",
       "      <td>61.583333</td>\n",
       "      <td>66.850000</td>\n",
       "      <td>710.443298</td>\n",
       "      <td>712.200928</td>\n",
       "      <td>709.344788</td>\n",
       "      <td>38000</td>\n",
       "      <td>468</td>\n",
       "      <td>310</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CND518</td>\n",
       "      <td>126.316667</td>\n",
       "      <td>131.583333</td>\n",
       "      <td>1611.395508</td>\n",
       "      <td>1613.115845</td>\n",
       "      <td>1610.394165</td>\n",
       "      <td>28750</td>\n",
       "      <td>469</td>\n",
       "      <td>327</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CND518</td>\n",
       "      <td>94.533333</td>\n",
       "      <td>99.800000</td>\n",
       "      <td>1153.938965</td>\n",
       "      <td>1155.678345</td>\n",
       "      <td>1152.899902</td>\n",
       "      <td>38000</td>\n",
       "      <td>466</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CND518</td>\n",
       "      <td>79.483333</td>\n",
       "      <td>84.750000</td>\n",
       "      <td>955.229919</td>\n",
       "      <td>956.982971</td>\n",
       "      <td>954.153259</td>\n",
       "      <td>38000</td>\n",
       "      <td>451</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CND518</td>\n",
       "      <td>25.450000</td>\n",
       "      <td>30.716667</td>\n",
       "      <td>203.243423</td>\n",
       "      <td>204.950699</td>\n",
       "      <td>202.057419</td>\n",
       "      <td>34375</td>\n",
       "      <td>483</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CND518</td>\n",
       "      <td>15.983333</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>86.925240</td>\n",
       "      <td>88.368912</td>\n",
       "      <td>85.766579</td>\n",
       "      <td>14275</td>\n",
       "      <td>384</td>\n",
       "      <td>290</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CND518</td>\n",
       "      <td>97.733333</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1199.453613</td>\n",
       "      <td>1201.191650</td>\n",
       "      <td>1198.417480</td>\n",
       "      <td>38000</td>\n",
       "      <td>465</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CND518</td>\n",
       "      <td>22.283333</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>162.852463</td>\n",
       "      <td>164.493820</td>\n",
       "      <td>161.657272</td>\n",
       "      <td>29350</td>\n",
       "      <td>455</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CND518</td>\n",
       "      <td>106.200000</td>\n",
       "      <td>111.466667</td>\n",
       "      <td>1320.907471</td>\n",
       "      <td>1322.640625</td>\n",
       "      <td>1319.881836</td>\n",
       "      <td>38000</td>\n",
       "      <td>477</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91274</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.616667</td>\n",
       "      <td>1.161670</td>\n",
       "      <td>2.295166</td>\n",
       "      <td>2.295166</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91275</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>64.983333</td>\n",
       "      <td>70.450000</td>\n",
       "      <td>665.882507</td>\n",
       "      <td>667.610596</td>\n",
       "      <td>667.610596</td>\n",
       "      <td>3850</td>\n",
       "      <td>237</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91276</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>57.183333</td>\n",
       "      <td>62.650000</td>\n",
       "      <td>591.340088</td>\n",
       "      <td>593.080322</td>\n",
       "      <td>593.080322</td>\n",
       "      <td>20550</td>\n",
       "      <td>420</td>\n",
       "      <td>334</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91277</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>33.983333</td>\n",
       "      <td>39.450000</td>\n",
       "      <td>274.831238</td>\n",
       "      <td>276.579102</td>\n",
       "      <td>276.579102</td>\n",
       "      <td>38000</td>\n",
       "      <td>481</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91278</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>21.183333</td>\n",
       "      <td>26.650000</td>\n",
       "      <td>135.818924</td>\n",
       "      <td>137.322968</td>\n",
       "      <td>137.322968</td>\n",
       "      <td>23100</td>\n",
       "      <td>341</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91279</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>16.916667</td>\n",
       "      <td>53.532955</td>\n",
       "      <td>54.460163</td>\n",
       "      <td>54.460163</td>\n",
       "      <td>8725</td>\n",
       "      <td>274</td>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91280</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>29.716667</td>\n",
       "      <td>35.183333</td>\n",
       "      <td>220.382309</td>\n",
       "      <td>222.093140</td>\n",
       "      <td>222.093140</td>\n",
       "      <td>35725</td>\n",
       "      <td>479</td>\n",
       "      <td>321</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91281</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>44.550000</td>\n",
       "      <td>50.016667</td>\n",
       "      <td>424.241364</td>\n",
       "      <td>426.000183</td>\n",
       "      <td>426.000183</td>\n",
       "      <td>35425</td>\n",
       "      <td>480</td>\n",
       "      <td>324</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91282</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>1.551501</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91283</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.616667</td>\n",
       "      <td>1.161670</td>\n",
       "      <td>2.295166</td>\n",
       "      <td>2.295166</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91284</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>53.133333</td>\n",
       "      <td>467.207092</td>\n",
       "      <td>468.964294</td>\n",
       "      <td>468.964294</td>\n",
       "      <td>34000</td>\n",
       "      <td>485</td>\n",
       "      <td>325</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91285</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>1.308269</td>\n",
       "      <td>2.083291</td>\n",
       "      <td>2.083291</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91286</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>53.966667</td>\n",
       "      <td>59.433333</td>\n",
       "      <td>552.495789</td>\n",
       "      <td>554.243835</td>\n",
       "      <td>554.243835</td>\n",
       "      <td>26550</td>\n",
       "      <td>461</td>\n",
       "      <td>339</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91287</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>44.716667</td>\n",
       "      <td>348.965057</td>\n",
       "      <td>350.722534</td>\n",
       "      <td>350.722534</td>\n",
       "      <td>38000</td>\n",
       "      <td>475</td>\n",
       "      <td>309</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91288</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>36.083333</td>\n",
       "      <td>41.550000</td>\n",
       "      <td>304.384583</td>\n",
       "      <td>306.138062</td>\n",
       "      <td>306.138062</td>\n",
       "      <td>38000</td>\n",
       "      <td>476</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91289</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>31.883333</td>\n",
       "      <td>37.350000</td>\n",
       "      <td>246.923889</td>\n",
       "      <td>248.660019</td>\n",
       "      <td>248.660019</td>\n",
       "      <td>38000</td>\n",
       "      <td>474</td>\n",
       "      <td>320</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91290</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>7.383333</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>31.406094</td>\n",
       "      <td>31.389174</td>\n",
       "      <td>31.389174</td>\n",
       "      <td>4625</td>\n",
       "      <td>229</td>\n",
       "      <td>266</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91291</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>35.083333</td>\n",
       "      <td>40.550000</td>\n",
       "      <td>290.224854</td>\n",
       "      <td>291.976105</td>\n",
       "      <td>291.976105</td>\n",
       "      <td>38000</td>\n",
       "      <td>478</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91292</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>69.150000</td>\n",
       "      <td>74.616667</td>\n",
       "      <td>662.409607</td>\n",
       "      <td>664.133484</td>\n",
       "      <td>664.133484</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91293</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>60.483333</td>\n",
       "      <td>65.950000</td>\n",
       "      <td>627.713257</td>\n",
       "      <td>629.446472</td>\n",
       "      <td>629.446472</td>\n",
       "      <td>12725</td>\n",
       "      <td>357</td>\n",
       "      <td>334</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91294</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>4.216667</td>\n",
       "      <td>9.683333</td>\n",
       "      <td>20.077810</td>\n",
       "      <td>19.298407</td>\n",
       "      <td>19.298407</td>\n",
       "      <td>2975</td>\n",
       "      <td>180</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91295</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>62.733333</td>\n",
       "      <td>68.200000</td>\n",
       "      <td>647.676147</td>\n",
       "      <td>649.405457</td>\n",
       "      <td>649.405457</td>\n",
       "      <td>7475</td>\n",
       "      <td>280</td>\n",
       "      <td>335</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91296</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>55.016667</td>\n",
       "      <td>60.483333</td>\n",
       "      <td>565.199646</td>\n",
       "      <td>566.944946</td>\n",
       "      <td>566.944946</td>\n",
       "      <td>24900</td>\n",
       "      <td>445</td>\n",
       "      <td>339</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91297</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>68.050000</td>\n",
       "      <td>73.516667</td>\n",
       "      <td>662.409607</td>\n",
       "      <td>664.133484</td>\n",
       "      <td>664.133484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91298</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>28.498869</td>\n",
       "      <td>28.103733</td>\n",
       "      <td>28.103733</td>\n",
       "      <td>4100</td>\n",
       "      <td>188</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91299</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>51.850000</td>\n",
       "      <td>57.316667</td>\n",
       "      <td>524.793579</td>\n",
       "      <td>526.546021</td>\n",
       "      <td>526.546021</td>\n",
       "      <td>29750</td>\n",
       "      <td>468</td>\n",
       "      <td>325</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91300</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>40.645931</td>\n",
       "      <td>41.202492</td>\n",
       "      <td>41.202492</td>\n",
       "      <td>6450</td>\n",
       "      <td>263</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91301</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>24.383333</td>\n",
       "      <td>29.850000</td>\n",
       "      <td>170.338760</td>\n",
       "      <td>171.883575</td>\n",
       "      <td>171.883575</td>\n",
       "      <td>26000</td>\n",
       "      <td>370</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91302</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>2.437929</td>\n",
       "      <td>2.437929</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>340</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91303</th>\n",
       "      <td>KL1798</td>\n",
       "      <td>13.516667</td>\n",
       "      <td>18.983333</td>\n",
       "      <td>66.344124</td>\n",
       "      <td>67.558052</td>\n",
       "      <td>67.558052</td>\n",
       "      <td>11150</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91304 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flight  time_till_landing_minutes  time_till_onblock_minutes  \\\n",
       "0      CND518                  95.616667                 100.883333   \n",
       "1      CND518                  73.116667                  78.383333   \n",
       "2      CND518                   0.000000                   2.100000   \n",
       "3      CND518                 100.883333                 106.150000   \n",
       "4      CND518                 136.083333                 141.350000   \n",
       "5      CND518                  72.150000                  77.416667   \n",
       "6      CND518                  27.550000                  32.816667   \n",
       "7      CND518                  50.983333                  56.250000   \n",
       "8      CND518                  47.816667                  53.083333   \n",
       "9      CND518                 112.466667                 117.733333   \n",
       "10     CND518                  82.733333                  88.000000   \n",
       "11     CND518                 111.450000                 116.716667   \n",
       "12     CND518                  86.000000                  91.266667   \n",
       "13     CND518                  12.816667                  18.083333   \n",
       "14     CND518                  35.950000                  41.216667   \n",
       "15     CND518                 129.883333                 135.150000   \n",
       "16     CND518                  66.850000                  72.116667   \n",
       "17     CND518                  24.383333                  29.650000   \n",
       "18     CND518                  52.083333                  57.350000   \n",
       "19     CND518                   4.250000                   9.516667   \n",
       "20     CND518                  81.583333                  86.850000   \n",
       "21     CND518                  61.583333                  66.850000   \n",
       "22     CND518                 126.316667                 131.583333   \n",
       "23     CND518                  94.533333                  99.800000   \n",
       "24     CND518                  79.483333                  84.750000   \n",
       "25     CND518                  25.450000                  30.716667   \n",
       "26     CND518                  15.983333                  21.250000   \n",
       "27     CND518                  97.733333                 103.000000   \n",
       "28     CND518                  22.283333                  27.550000   \n",
       "29     CND518                 106.200000                 111.466667   \n",
       "...       ...                        ...                        ...   \n",
       "91274  KL1798                   0.000000                   2.616667   \n",
       "91275  KL1798                  64.983333                  70.450000   \n",
       "91276  KL1798                  57.183333                  62.650000   \n",
       "91277  KL1798                  33.983333                  39.450000   \n",
       "91278  KL1798                  21.183333                  26.650000   \n",
       "91279  KL1798                  11.450000                  16.916667   \n",
       "91280  KL1798                  29.716667                  35.183333   \n",
       "91281  KL1798                  44.550000                  50.016667   \n",
       "91282  KL1798                   0.000000                   5.466667   \n",
       "91283  KL1798                   0.000000                   2.616667   \n",
       "91284  KL1798                  47.666667                  53.133333   \n",
       "91285  KL1798                   0.000000                   3.366667   \n",
       "91286  KL1798                  53.966667                  59.433333   \n",
       "91287  KL1798                  39.250000                  44.716667   \n",
       "91288  KL1798                  36.083333                  41.550000   \n",
       "91289  KL1798                  31.883333                  37.350000   \n",
       "91290  KL1798                   7.383333                  12.850000   \n",
       "91291  KL1798                  35.083333                  40.550000   \n",
       "91292  KL1798                  69.150000                  74.616667   \n",
       "91293  KL1798                  60.483333                  65.950000   \n",
       "91294  KL1798                   4.216667                   9.683333   \n",
       "91295  KL1798                  62.733333                  68.200000   \n",
       "91296  KL1798                  55.016667                  60.483333   \n",
       "91297  KL1798                  68.050000                  73.516667   \n",
       "91298  KL1798                   6.300000                  11.766667   \n",
       "91299  KL1798                  51.850000                  57.316667   \n",
       "91300  KL1798                   9.400000                  14.866667   \n",
       "91301  KL1798                  24.383333                  29.850000   \n",
       "91302  KL1798                   0.000000                   0.500000   \n",
       "91303  KL1798                  13.516667                  18.983333   \n",
       "\n",
       "       distance_to_ams  distance_to_runway  distance_to_pier  altitude  speed  \\\n",
       "0          1169.708008         1171.446899       1168.669922     38000    465   \n",
       "1           873.840332          875.597168        872.747070     38000    456   \n",
       "2             0.560867            1.426841          1.505711         0      0   \n",
       "3          1244.882324         1246.619141       1243.848999     38000    476   \n",
       "4          1726.118042         1727.837769       1725.117798     10850    314   \n",
       "5           859.987732          861.744568        858.894226     38000    456   \n",
       "6           231.215576          232.944443        230.040207     36000    473   \n",
       "7           559.123230          560.881836        558.015015     38000    464   \n",
       "8           514.278992          516.037781        513.166992     38000    459   \n",
       "9          1408.481812         1410.208984       1407.467896     38000    479   \n",
       "10          996.119568          997.869385        995.053528     38000    449   \n",
       "11         1393.996826         1395.724609       1392.981934     38000    477   \n",
       "12         1037.474609         1039.220947       1036.418579     38000    453   \n",
       "13           56.418419           57.591949         55.363499      7725    320   \n",
       "14          347.197021          348.953766        346.062073     38000    469   \n",
       "15         1658.515015         1660.237915       1657.509033     24000    420   \n",
       "16          785.348999          787.106201        784.253723     38000    461   \n",
       "17          189.109848          190.800507        187.919189     33350    486   \n",
       "18          574.542786          576.301331        573.435791     38000    463   \n",
       "19           16.019865           15.226078         16.241917      2200    177   \n",
       "20          981.617554          983.368530        980.547852     38000    450   \n",
       "21          710.443298          712.200928        709.344788     38000    468   \n",
       "22         1611.395508         1613.115845       1610.394165     28750    469   \n",
       "23         1153.938965         1155.678345       1152.899902     38000    466   \n",
       "24          955.229919          956.982971        954.153259     38000    451   \n",
       "25          203.243423          204.950699        202.057419     34375    483   \n",
       "26           86.925240           88.368912         85.766579     14275    384   \n",
       "27         1199.453613         1201.191650       1198.417480     38000    465   \n",
       "28          162.852463          164.493820        161.657272     29350    455   \n",
       "29         1320.907471         1322.640625       1319.881836     38000    477   \n",
       "...                ...                 ...               ...       ...    ...   \n",
       "91274         1.161670            2.295166          2.295166         0     19   \n",
       "91275       665.882507          667.610596        667.610596      3850    237   \n",
       "91276       591.340088          593.080322        593.080322     20550    420   \n",
       "91277       274.831238          276.579102        276.579102     38000    481   \n",
       "91278       135.818924          137.322968        137.322968     23100    341   \n",
       "91279        53.532955           54.460163         54.460163      8725    274   \n",
       "91280       220.382309          222.093140        222.093140     35725    479   \n",
       "91281       424.241364          426.000183        426.000183     35425    480   \n",
       "91282         1.551501            0.470344          0.470344         0     25   \n",
       "91283         1.161670            2.295166          2.295166         0     19   \n",
       "91284       467.207092          468.964294        468.964294     34000    485   \n",
       "91285         1.308269            2.083291          2.083291         0     24   \n",
       "91286       552.495789          554.243835        554.243835     26550    461   \n",
       "91287       348.965057          350.722534        350.722534     38000    475   \n",
       "91288       304.384583          306.138062        306.138062     38000    476   \n",
       "91289       246.923889          248.660019        248.660019     38000    474   \n",
       "91290        31.406094           31.389174         31.389174      4625    229   \n",
       "91291       290.224854          291.976105        291.976105     38000    478   \n",
       "91292       662.409607          664.133484        664.133484         0      2   \n",
       "91293       627.713257          629.446472        629.446472     12725    357   \n",
       "91294        20.077810           19.298407         19.298407      2975    180   \n",
       "91295       647.676147          649.405457        649.405457      7475    280   \n",
       "91296       565.199646          566.944946        566.944946     24900    445   \n",
       "91297       662.409607          664.133484        664.133484         0      0   \n",
       "91298        28.498869           28.103733         28.103733      4100    188   \n",
       "91299       524.793579          526.546021        526.546021     29750    468   \n",
       "91300        40.645931           41.202492         41.202492      6450    263   \n",
       "91301       170.338760          171.883575        171.883575     26000    370   \n",
       "91302         0.685573            2.437929          2.437929         0     15   \n",
       "91303        66.344124           67.558052         67.558052     11150    291   \n",
       "\n",
       "       heading  runway_touchdown  pier_onblock  \n",
       "0          322                 8             5  \n",
       "1          309                 8             5  \n",
       "2          326                 8             5  \n",
       "3          322                 8             5  \n",
       "4          343                 8             5  \n",
       "5          309                 8             5  \n",
       "6          311                 8             5  \n",
       "7          309                 8             5  \n",
       "8          308                 8             5  \n",
       "9          327                 8             5  \n",
       "10         335                 8             5  \n",
       "11         327                 8             5  \n",
       "12         335                 8             5  \n",
       "13         276                 8             5  \n",
       "14         312                 8             5  \n",
       "15         302                 8             5  \n",
       "16         309                 8             5  \n",
       "17         311                 8             5  \n",
       "18         309                 8             5  \n",
       "19         183                 8             5  \n",
       "20         336                 8             5  \n",
       "21         310                 8             5  \n",
       "22         327                 8             5  \n",
       "23         322                 8             5  \n",
       "24         336                 8             5  \n",
       "25         311                 8             5  \n",
       "26         290                 8             5  \n",
       "27         322                 8             5  \n",
       "28         311                 8             5  \n",
       "29         336                 8             5  \n",
       "...        ...               ...           ...  \n",
       "91274       56                 2             2  \n",
       "91275        6                 2             2  \n",
       "91276      334                 2             2  \n",
       "91277      312                 2             2  \n",
       "91278      280                 2             2  \n",
       "91279      279                 2             2  \n",
       "91280      321                 2             2  \n",
       "91281      324                 2             2  \n",
       "91282      154                 2             2  \n",
       "91283       56                 2             2  \n",
       "91284      325                 2             2  \n",
       "91285      132                 2             2  \n",
       "91286      339                 2             2  \n",
       "91287      309                 2             2  \n",
       "91288      313                 2             2  \n",
       "91289      320                 2             2  \n",
       "91290      266                 2             2  \n",
       "91291      313                 2             2  \n",
       "91292      351                 2             2  \n",
       "91293      334                 2             2  \n",
       "91294      185                 2             2  \n",
       "91295      335                 2             2  \n",
       "91296      339                 2             2  \n",
       "91297       56                 2             2  \n",
       "91298      264                 2             2  \n",
       "91299      325                 2             2  \n",
       "91300      271                 2             2  \n",
       "91301      281                 2             2  \n",
       "91302      340                 2             2  \n",
       "91303      291                 2             2  \n",
       "\n",
       "[91304 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create our machine learing dataset\n",
    "ml_df = join_df.select(['flight','time_till_landing_minutes','time_till_onblock_minutes','distance_to_ams','distance_to_runway','distance_to_pier','altitude','speed','heading','runway_touchdown','pier_onblock'])\n",
    "#ml_df = ml_df.withColumn('id',fn.monotonically_increasing_id())\n",
    "ml_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove later!!!! just to test, we remove all flights to far away from our onblock locations\n",
    "ml_df = ml_df.join(ok_df,ok_df.flight_ok == ml_df.flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = ml_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ml_df.toPandas().to_csv('/root/fr24/fr24.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#Change label to time_till_landing_minutes if you want to predict that field\n",
    "assembler = VectorAssembler(inputCols=[\"distance_to_runway\",\"altitude\",\"speed\",\"heading\",\"runway_touchdown\"],outputCol=\"features\")\n",
    "Regressor = DecisionTreeRegressor(featuresCol=\"features\",labelCol=\"time_till_landing_minutes\",maxDepth=25)\n",
    "pipeline = Pipeline(stages=[assembler,Regressor])\n",
    "model = pipeline.fit(training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testing_data)\n",
    "modelEvaluator = RegressionEvaluator(labelCol=\"time_till_landing_minutes\")\n",
    "modelError = modelEvaluator.evaluate(predictions) #rmse by default\n",
    "modelError = modelEvaluator.evaluate(predictions,{modelEvaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelError #time landing 4,5 minutes, 6,5 minutes for onblock time. Will try to improve using pier for parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.toPandas().head(100) #show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on block time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#We only predict onblock and have extra field pier_onblock\n",
    "assembler = VectorAssembler(inputCols=[\"distance_to_pier\",\"speed\",\"altitude\",\"heading\",\"runway_touchdown\"],outputCol=\"features\")\n",
    "Regressor = DecisionTreeRegressor(featuresCol=\"features\",labelCol=\"time_till_onblock_minutes\",maxDepth=25)\n",
    "pipeline = Pipeline(stages=[assembler,Regressor])\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testing_data)\n",
    "modelEvaluator = RegressionEvaluator(labelCol=\"time_till_onblock_minutes\")\n",
    "modelError = modelEvaluator.evaluate(predictions,{modelEvaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.219288612080106"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelError  # WOW!! 4.2 , so this suggest if we use actual gate information predictions are very nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some distance_to_pier is 3 km while time till onblock is 0, so either we doe something wrong or its not on our piers\n",
    "predictions.toPandas().query(\"time_till_onblock_minutes < 0.1 and speed == 0\").head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets try random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"distance_to_ams\",\"speed\",\"altitude\",\"heading\",\"runway\"],outputCol=\"features\")\n",
    "Regressor = RandomForestRegressor(featuresCol=\"features\",labelCol=\"time_till_landing_minutes\",maxDepth=5)\n",
    "\n",
    "#pipeline = Pipeline(stages=[isLondonIndexer,durationIndexer,typeIndexer,assembler,Regressor])\n",
    "pipeline = Pipeline(stages=[assembler,Regressor])\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test again with new model\n",
    "predictions = model.transform(testing_data)\n",
    "modelEvaluator = RegressionEvaluator(labelCol=\"time_till_landing_minutes\")\n",
    "modelError = modelEvaluator.evaluate(predictions) #rmse by default\n",
    "modelError = modelEvaluator.evaluate(predictions,{modelEvaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#22 mins with default settings depth 5, 9 mins with depth 10.\n",
    "#6,4 with depth 15. Crashed with 20 depth on mac\n",
    "modelError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid-search first , later train validation\n",
    "grid = tune.ParamGridBuilder() \\\n",
    "       .addGrid(logistic.maxIter,\n",
    "                [2, 10, 50]) \\\n",
    "       .addGrid(logistic.regParam,\n",
    "                [0.01, 0.05, 0.3]) \\\n",
    "       .build()\n",
    "    \n",
    "evaluator = ev.BinaryClassificationEvaluator( \\\n",
    "       rawPredictionCol='probability', \\\n",
    "       labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "    \n",
    "cv = tune.CrossValidator( \\\n",
    "       estimator=logistic, \\\n",
    "       estimatorParamMaps=grid, \\\n",
    "       evaluator=evaluator\n",
    ")\n",
    "    \n",
    "pipeline = Pipeline(stages=[encoder ,featuresCreator])\n",
    "data_transformer = pipeline.fit(births_train)\n",
    "cvModel = cv.fit(data_transformer.transform(births_train))\n",
    "\n",
    "data_train = data_transformer \\\n",
    "       .transform(births_test)\n",
    "results = cvModel.transform(data_train)\n",
    "print(evaluator.evaluate(results, \\\n",
    "        {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, \\\n",
    "        {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification example\n",
    "\n",
    "```\n",
    "import pyspark.ml.classification as cl\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "encoder = ft.OneHotEncoder(\n",
    "       inputCol='BIRTH_PLACE_INT',\n",
    "       outputCol='BIRTH_PLACE_VEC')\n",
    "       \n",
    "\n",
    "logistic = cl.LogisticRegression(\n",
    "       maxIter=10,\n",
    "       regParam=0.01,\n",
    "       labelCol='some_classifation')\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "           encoder,\n",
    "           featuresCreator,logistic ])\n",
    "    \n",
    "births_train, births_test = births \\\n",
    "       .randomSplit([0.7, 0.3], seed=666)\n",
    "    \n",
    "model = pipeline.fit(births_train)\n",
    "test_model = model.transform(births_test)  \n",
    "\n",
    "valuator = ev.BinaryClassificationEvaluator(\n",
    "       rawPredictionCol='probability',\n",
    "       labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "       \n",
    "pipelinePath = './infant_oneHotEncoder_Logistic_Pipeline'\n",
    "pipeline.write().overwrite().save(pipelinePath)\n",
    "\n",
    "to load:\n",
    "loadedPipeline = Pipeline.load(pipelinePath)\n",
    "loadedPipeline \\\n",
    "       .fit(births_train)\\\n",
    "       .transform(births_test)\\\n",
    "       .take(1)\n",
    "       \n",
    "       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "What would happen if we have a string based column?\n",
    "\n",
    "Make it a number\n",
    "births = births \\\n",
    "       .withColumn('BIRTH_PLACE_INT', births['BIRTH_PLACE'] \\\n",
    "       .cast(typ.IntegerType()))\n",
    "       \n",
    "       \n",
    "   encoder = ft.OneHotEncoder(\n",
    "       inputCol='BIRTH_PLACE_INT',\n",
    "       outputCol='BIRTH_PLACE_VEC')\n",
    "       \n",
    "Like before create the assembler, but we use getoutputcol so we \n",
    "dont care about the real column name:\n",
    "   featuresCreator = ft.VectorAssembler(\n",
    "       inputCols=[\n",
    "           col[0]\n",
    "           for col\n",
    "           in labels[2:]] + \\\n",
    "       [encoder.getOutputCol()],\n",
    "     outputCol='features'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import bokeh.charts as chrt\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml_df.where(\"time_till_landing_minutes < 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hists = ml_df.select('time_till_landing_minutes').rdd.flatMap(\n",
    "       lambda row: row\n",
    ").histogram(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_hist = {\n",
    "       'bins': hists[0][:-1],\n",
    "       'freq': hists[1]\n",
    "   }\n",
    "plt.bar(data_hist['bins'], data_hist['freq'], width=20)\n",
    "plt.title('Histogram of \\'time_till_landing\\'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b_hist = chrt.Bar(\n",
    "       data_hist,\n",
    "       values='freq', label='bins',\n",
    "       title='Histogram of \\'balance\\'')\n",
    "chrt.show(b_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_back = 0.001\n",
    "\n",
    "# use this if you want an (almost) exact number of samples\n",
    "# sample_count = 200\n",
    "# percent_back = sample_count / posts.count()\n",
    "\n",
    "frac = dict(\n",
    "    (e.time_till_landing_minutes, percent_back) \n",
    "    for e \n",
    "    in ml_df.select('time_till_landing_minutes').distinct().collect()\n",
    ")\n",
    "sampled = ml_df.sampleBy('time_till_landing_minutes', fractions=frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sampled.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
